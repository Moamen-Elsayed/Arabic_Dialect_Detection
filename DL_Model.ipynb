{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "1-Jgy0kJ93Db"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input, concatenate, Bidirectional\n",
        "from keras.layers import Embedding, SpatialDropout1D, BatchNormalization\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D, LSTM, GRU\n",
        "from keras.callbacks import EarlyStopping\n",
        "from importlib import import_module\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn import preprocessing\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import losses\n",
        "from keras import metrics\n",
        "from keras import optimizers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbDO51BmnaJy",
        "outputId": "02a282b4-3f74-468f-e514-203889b5559e"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "OU39g97Hi-rK"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaiOqk2PfPdJ",
        "outputId": "1cd48332-e209-4d0c-ddc8-38bbbadb05e0"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"/content/drive/MyDrive/balanced_dataset.csv\")"
      ],
      "metadata": {
        "id": "ykeVOTTofQw1"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 40000\n",
        "mx_len = 250\n",
        "emd_dim = 100\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(dataset['cleaned_tweet'].values)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA8JOJSqn6tI",
        "outputId": "4c590608-e176-4174-e03e-e9af4cca7fff"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 241352 unique tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = tokenizer.texts_to_sequences(dataset['cleaned_tweet'].values)\n",
        "X = pad_sequences(X, maxlen=mx_len)\n",
        "print('Shape of data:', X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Uw7-a1ZsbiE",
        "outputId": "54d28929-7376-4fb0-db8d-a75ba3bf6fbf"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data: (166428, 250)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = pd.get_dummies(dataset['dialect']).values\n",
        "print('Shape of label:', y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYOJ2BiTsf7X",
        "outputId": "e5be2ea6-f562-4091-addf-b77593d224d3"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of label: (166428, 18)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2022)\n",
        "\n",
        "print(X_train.shape,y_train.shape)\n",
        "print(X_test.shape,y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glrl_AAyfylr",
        "outputId": "478f7e6f-cede-42fa-e361-1f145b28b8c9"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(133142, 250) (133142, 18)\n",
            "(33286, 250) (33286, 18)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp = Input(shape = (mx_len,))\n",
        "x = Embedding(vocab_size, emd_dim, input_length=X.shape[1])(inp)\n",
        "# x_lstm = Bidirectional(LSTM(128, return_sequences = True))(x)\n",
        "# x_lstm_c1d = Conv1D(64,kernel_size=3,padding='valid',activation='tanh')(x_lstm)\n",
        "# x_lstm_c1d_gp = GlobalMaxPooling1D()(x_lstm_c1d)\n",
        "\n",
        "x_gru = Bidirectional(GRU(128, return_sequences = True))(x)\n",
        "x_gru_c1d = Conv1D(64,kernel_size=2,padding='valid',activation='tanh')(x_gru)\n",
        "x_gru_c1d_gp = GlobalMaxPooling1D()(x_gru_c1d)\n",
        "\n",
        "# x_f = concatenate([x_lstm_c1d_gp, x_gru_c1d_gp])\n",
        "# x_f = BatchNormalization()(x_f)\n",
        "# x_f =(Dense(128, activation='tanh') (x_f))    \n",
        "# x_f = BatchNormalization()(x_f)\n",
        "\n",
        "x_f = BatchNormalization()(x_gru_c1d_gp)\n",
        "x_f =(Dense(128, activation='tanh') (x_f))    \n",
        "x_f = BatchNormalization()(x_f)\n",
        "\n",
        "x_f = (Dense(64, activation='tanh') (x_f))\n",
        "x_f = (Dense(18, activation='softmax'))(x_f)\n",
        "model = Model(inputs = [inp], outputs = x_f)"
      ],
      "metadata": {
        "id": "BgpjI2rXrYrX"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "my_optimizer = tf.keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.99, decay=0.01)\n",
        "reduceLR = ReduceLROnPlateau(monitor='accuracy', factor=0.1, patience=3, verbose=1)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=my_optimizer, metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqi6rFwzgZnl",
        "outputId": "6901c8a5-dc38-454b-88ca-041de5b28576"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_21 (InputLayer)       [(None, 250)]             0         \n",
            "                                                                 \n",
            " embedding_23 (Embedding)    (None, 250, 100)          4000000   \n",
            "                                                                 \n",
            " bidirectional_26 (Bidirecti  (None, 250, 256)         176640    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " conv1d_17 (Conv1D)          (None, 249, 64)           32832     \n",
            "                                                                 \n",
            " global_max_pooling1d_17 (Gl  (None, 64)               0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 64)               256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " batch_normalization_21 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 18)                1170      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,227,986\n",
            "Trainable params: 4,227,602\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, batch_size=512, epochs=4, shuffle=True,\n",
        "                             validation_data=[X_test, y_test], verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQhN0h8l6aks",
        "outputId": "0d563102-2c9d-4991-f182-1b0e2633a2ec"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "261/261 [==============================] - 79s 287ms/step - loss: 2.9151 - accuracy: 0.0941 - val_loss: 2.8605 - val_accuracy: 0.1188\n",
            "Epoch 2/4\n",
            "261/261 [==============================] - 74s 283ms/step - loss: 2.7107 - accuracy: 0.1614 - val_loss: 2.7454 - val_accuracy: 0.1582\n",
            "Epoch 3/4\n",
            "261/261 [==============================] - 74s 283ms/step - loss: 2.6165 - accuracy: 0.1965 - val_loss: 2.6773 - val_accuracy: 0.1744\n",
            "Epoch 4/4\n",
            "261/261 [==============================] - 74s 284ms/step - loss: 2.5522 - accuracy: 0.2205 - val_loss: 2.6413 - val_accuracy: 0.1863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"DL_model.h5\")"
      ],
      "metadata": {
        "id": "QUyTCvLo8XJk"
      },
      "execution_count": 115,
      "outputs": []
    }
  ]
}